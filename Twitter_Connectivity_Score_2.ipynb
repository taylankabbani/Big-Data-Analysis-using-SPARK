{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from time import time\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TWITTER():\n",
    "    def __init__(self, directory):\n",
    "        \n",
    "        # if two users are following each other, counts are increased by 0.5, otherwise 1\n",
    "        self.following = sc.textFile(directory) \\\n",
    "                                .map(lambda x: (x.split(\" \"*4)[0], x.split(\" \"*4)[1])) \\\n",
    "                                .map(lambda x: (sorted(x)[0]+sorted(x)[1],x[0])) \\\n",
    "                                .groupByKey() \\\n",
    "                                .flatMap(lambda x: [(list(x[1])[i],0.5) for i in range(len(x[1]))] if len(x[1])> 1 \n",
    "                                         else [(list(x[1])[0], 1)]) \\\n",
    "                                .combineByKey((lambda x: x),\n",
    "                                              # using combiner to minimize data shuffled across servers \n",
    "                                             (lambda x,y: x + y),\n",
    "                                             (lambda x,y: x + y)).persist()\n",
    "        \n",
    "        \n",
    "        self.followers = sc.textFile(directory) \\\n",
    "                                .map(lambda x: (x.split(\" \"*4)[0], x.split(\" \"*4)[1])) \\\n",
    "                                .map(lambda x: (sorted(x)[0]+sorted(x)[1],x[1])) \\\n",
    "                                .groupByKey() \\\n",
    "                                .flatMap(lambda x: [(list(x[1])[i],0.5) for i in range(len(x[1]))] if len(x[1])> 1 \n",
    "                                         else [(list(x[1])[0], 1)]) \\\n",
    "                                .combineByKey((lambda x: x),\n",
    "                                              # using combiner to minimize data shuffled across servers \n",
    "                                             (lambda x,y: x + y),\n",
    "                                             (lambda x,y: x + y))\n",
    "        \n",
    "    # Calculate each userâ€™s score (N*M)\n",
    "    def user_score(self):\n",
    "        s = self.following.join(self.followers).mapValues(lambda x: x[0] * x[1])\n",
    "        return s\n",
    "    \n",
    "    # Save results as CSV \n",
    "    def save_file(self, file_name):\n",
    "        with open(file_name, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(self.user_score().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('user624', 309559.25), ('user8297', 186441.75), ('user3525', 365295.0), ('user6101', 362428.75), ('user7431', 261100.75)]\n"
     ]
    }
   ],
   "source": [
    "data = TWITTER(r\"C:\\Users\\taylankabbani2019\\Downloads\\Connectivity_Score\\*\")\n",
    "\n",
    "print(data.user_score().take(5))\n",
    "\n",
    "# data.save_file('Connectivity_Scores')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
