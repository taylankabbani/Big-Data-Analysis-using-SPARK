{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TWITTER():\n",
    "    def __init__(self, directory):\n",
    "         # For each user create key/value pairs,(current_user ,#users followed by current_user)\n",
    "        self.following = sc.textFile(directory).map(lambda x: (x.split(\" \"*4)[0], 1)) \\\n",
    "                                               .combineByKey((lambda x: x),\n",
    "                                                             # using combiner to minimize data shuffled across servers \n",
    "                                                             (lambda x,y: x + y),\n",
    "                                                             (lambda x,y: x + y)) \\\n",
    "                                               .persist()\n",
    "        \n",
    "        # For each user create key/value pairs,(current_user ,#followers)\n",
    "        self.followers = sc.textFile(directory).map(lambda x: (x.split(\" \"*4)[1], 1)) \\\n",
    "                                               .combineByKey((lambda x: x),\n",
    "                                                             (lambda x,y: x + y),\n",
    "                                                             (lambda x,y: x + y))\n",
    "    # Calculate each user’s score (N*M)\n",
    "    def user_score(self):\n",
    "        s = self.following.join(self.followers).mapValues(lambda x: x[0] * x[1])\n",
    "        return s\n",
    "    \n",
    "    # Save results as CSV \n",
    "    def save_file(self, file_name):\n",
    "        with open(file_name, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(self.user_score().collect())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('user4686', 293910), ('user280', 65604), ('user1611', 456918), ('user376', 233618), ('user2302', 10120)]\n"
     ]
    }
   ],
   "source": [
    "data = TWITTER(r\"C:\\Users\\taylankabbani2019\\Downloads\\Connectivity_Score\\*\")\n",
    "\n",
    "print(data.user_score().take(5))\n",
    "\n",
    "# data.save_file('Connectivity_Score')\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spark DataFrame and DataFrame operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TWITTER_df():\n",
    "    def __init__(self, directory):\n",
    "        # Creating DataFrame with 2 columns (‘userA’ and ‘userB’) from the input RDD\n",
    "        self.df = sql.createDataFrame(sc.textFile(directory).map(lambda x: (x.split(\" \"*4)[0], x.split(\" \"*4)[1])) \\\n",
    "                                        .map(lambda rdd: Row(userA = rdd[0],\n",
    "                                                            userB = rdd[1])))\n",
    "    def user_score(self):\n",
    "        \n",
    "        # Dataframe represents number of users followed by each user\n",
    "        following = self.df.groupBy('userA').count().withColumnRenamed('userA','user').persist()\n",
    "        \n",
    "        # Dataframe represents number of followers of each user\n",
    "        followers = self.df.groupBy('userB').count().withColumnRenamed('userB','user')\n",
    "        \n",
    "        # Calculate each user’s score (N*M)\n",
    "        return following.join(followers, 'user').rdd.map(lambda x: (x[0],x[1]*x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('user108', 42120), ('user1222', 395760), ('user1270', 262521), ('user1564', 423864), ('user1590', 415826)]\n"
     ]
    }
   ],
   "source": [
    "data = TWITTER_df(r\"C:\\Users\\taylankabbani2019\\Downloads\\Connectivity_Score\\*\")\n",
    "print(data.user_score().take(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
